# -*- coding: utf-8 -*-
"""Colpali Multimodal RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p8JllI1uGkk97v31EBvuVN8Q2OWgeGUT
"""

# 0) ORTAMI HAZIRLA  (tek sefer)
!apt-get -y install poppler-utils
!pip install pdf2image faiss-cpu colpali_engine google-generativeai
!pip install PyMuPDF
!pip install pdf2image pillow --quiet
!apt-get update -qq && apt-get install -y poppler-utils -qq
!pip install pymilvus

### Gerekli kütüphaneleri yükle

from colpali_engine.models import ColPali
from colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor
from colpali_engine.utils.processing_utils import BaseVisualRetrieverProcessor
from colpali_engine.utils.torch_utils import ListDataset, get_torch_device
from torch.utils.data import DataLoader
import torch
from typing import List, cast
from tqdm import tqdm
from PIL import Image
import os
import requests
import os
import google.generativeai as genai
from typing import List
from PIL import Image
import gradio as gr
import tempfile
import os
import fitz  # PyMuPDF
import uuid
from pdf2image import convert_from_path
import shutil
import os, shutil

### PDF'leri yükleme, Image için klasör oluşturma, Image kaydetme
from pdf2image import convert_from_path
class PdfManager:
    def __init__(self):
        pass

    def clear_and_recreate_dir(self, output_folder):
        print(f"Clearing output folder {output_folder}")

        if os.path.exists(output_folder):
            shutil.rmtree(output_folder)

        os.makedirs(output_folder)

    def save_images(self, id, pdf_path, max_pages, pages: list[int] = None) -> list[str]:
        output_folder = f"pages/{id}/"
        images = convert_from_path(pdf_path)

        print(f"Saving images from {pdf_path} to {output_folder}. Max pages: {max_pages}")

        self.clear_and_recreate_dir(output_folder)

        num_page_processed = 0

        for i, image in enumerate(images):
            if max_pages and num_page_processed >= max_pages:
                break

            if pages and i not in pages:
                continue

            full_save_path = f"{output_folder}/page_{i + 1}.png"

            #print(f"Saving image to {full_save_path}")

            image.save(full_save_path, "PNG")

            num_page_processed += 1

        return [f"{output_folder}/page_{i + 1}.png" for i in range(num_page_processed)]

#### Colpali / Model İndirme ve Embed İşlemleri

from colpali_engine.models import ColPali
from colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor
from colpali_engine.utils.processing_utils import BaseVisualRetrieverProcessor
from colpali_engine.utils.torch_utils import ListDataset, get_torch_device
from torch.utils.data import DataLoader
import torch
from typing import List, cast

from tqdm import tqdm
from PIL import Image
import os


model_name = "vidore/colpali-v1.2"
device = get_torch_device("cuda")

model = ColPali.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map=device,
).eval()

processor = cast(ColPaliProcessor, ColPaliProcessor.from_pretrained(model_name))

class ColpaliManager:


    def __init__(self, device = "cuda", model_name = "vidore/colpali-v1.2"):

        print(f"Initializing ColpaliManager with device {device} and model {model_name}")

    def get_images(self, paths: list[str]) -> List[Image.Image]:
        return [Image.open(path) for path in paths]

    def process_images(self, image_paths:list[str], batch_size=5):

        print(f"Processing {len(image_paths)} image_paths")

        images = self.get_images(image_paths)

        dataloader = DataLoader(
            dataset=ListDataset[str](images),
            batch_size=batch_size,
            shuffle=False,
            collate_fn=lambda x: processor.process_images(x),
        )

        ds: List[torch.Tensor] = []
        for batch_doc in tqdm(dataloader):
            with torch.no_grad():
                batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}
                embeddings_doc = model(**batch_doc)
            ds.extend(list(torch.unbind(embeddings_doc.to(device))))

        ds_np = [d.float().cpu().numpy() for d in ds]

        return ds_np

    def process_text(self, texts: list[str]):
        print(f"Processing {len(texts)} texts")

        dataloader = DataLoader(
            dataset=ListDataset[str](texts),
            batch_size=1,
            shuffle=False,
            collate_fn=lambda x: processor.process_queries(x),
        )

        qs: List[torch.Tensor] = []
        for batch_query in dataloader:
            with torch.no_grad():
                batch_query = {k: v.to(model.device) for k, v in batch_query.items()}
                embeddings_query = model(**batch_query)

            qs.extend(list(torch.unbind(embeddings_query.to(device))))

        qs_np = [q.float().cpu().numpy() for q in qs]

        return qs_np

#### pymilvus embedding and searching

from pymilvus import MilvusClient, DataType
import numpy as np
import concurrent.futures


class MilvusManager:
    def __init__(self, milvus_uri, collection_name, create_collection, dim=128):
        self.client = MilvusClient(uri=milvus_uri)
        self.collection_name = collection_name
        # Check if collection exists and load it if not creating a new one
        if not create_collection and self.client.has_collection(collection_name=self.collection_name):
             self.client.load_collection(collection_name)

        self.dim = dim

        if create_collection:
            self.create_collection()
            self.create_index()


    def create_collection(self):
        # drop collection if it exists and create a new one
        if self.client.has_collection(collection_name=self.collection_name):
            self.client.drop_collection(collection_name=self.collection_name)
        schema = self.client.create_schema(
            auto_id=True,
            enable_dynamic_fields=True,
        )
        schema.add_field(field_name="pk", datatype=DataType.INT64, is_primary=True)
        schema.add_field(
            field_name="vector", datatype=DataType.FLOAT_VECTOR, dim=self.dim
        )
        schema.add_field(field_name="seq_id", datatype=DataType.INT16)
        schema.add_field(field_name="doc_id", datatype=DataType.INT64)
        schema.add_field(field_name="doc", datatype=DataType.VARCHAR, max_length=65535)

        self.client.create_collection(
            collection_name=self.collection_name, schema=schema
        )

    def create_index(self):
        # Release the collection before creating an index
        self.client.release_collection(collection_name=self.collection_name)

        # Prepare and create the index
        index_params = self.client.prepare_index_params()
        index_params.add_index(
            field_name="vector",
            index_name="vector_index",
            index_type="FLAT",  # Using FLAT index as a starting point
            metric_type="IP",
            params={
                "M": 16, # These parameters are specific to HNSW, might need adjustment for FLAT
                "efConstruction": 500,
            },
        )

        self.client.create_index(
            collection_name=self.collection_name, index_params=index_params, sync=True
        )

    def create_scalar_index(self):
        self.client.release_collection(collection_name=self.collection_name)
        index_params = self.client.prepare_index_params()
        index_params.add_index(
            field_name="doc_id",
            index_name="int32_index",
            index_type="FLAT",
        )

        self.client.create_index(
            collection_name=self.collection_name, index_params=index_params, sync=True
        )


    def search(self, data, topk):
        search_params = {"metric_type": "IP", "params": {}}
        results = self.client.search(
            self.collection_name,
            data,
            limit=int(50),
            output_fields=["vector", "seq_id", "doc_id"],
            search_params=search_params,
        )
        doc_ids = set()
        for r_id in range(len(results)):
            for r in range(len(results[r_id])):
                doc_ids.add(results[r_id][r]["entity"]["doc_id"])

        scores = []

        def rerank_single_doc(doc_id, data, client, collection_name):
            doc_colbert_vecs = client.query(
                collection_name=collection_name,
                filter=f"doc_id in [{doc_id}]",
                output_fields=["seq_id", "vector", "doc"], # Ensure 'doc' is requested here
                limit=1000,
            )
            if not doc_colbert_vecs: # Added check for empty results
                return (0, doc_id) # Return a score of 0 if no vectors are found

            doc_vecs = np.vstack(
                [doc_colbert_vecs[i]["vector"] for i in range(len(doc_colbert_vecs))]
            )
            score = np.dot(data, doc_vecs.T).max(1).sum()
            return (score, doc_id)

        with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:
            futures = {
                executor.submit(
                    rerank_single_doc, doc_id, data, self.client, self.collection_name
                ): doc_id
                for doc_id in doc_ids
            }
            for future in concurrent.futures.as_completed(futures):
                score, doc_id = future.result()
                scores.append((score, doc_id))

        scores.sort(key=lambda x: x[0], reverse=True)
        if len(scores) >= topk:
            return scores[:topk]
        else:
            return scores

    def insert_images_data(self, image_data):
        # image_data is a list of dictionaries, each with 'colbert_vecs' and 'filepath'
        entities = []
        for i, data in enumerate(image_data):
            colbert_vecs = data["colbert_vecs"]
            filepath = data["filepath"]
            seq_length = len(colbert_vecs)
            for j in range(seq_length):
                entities.append({
                    "vector": colbert_vecs[j],
                    "seq_id": j,
                    "doc_id": i, # doc_id corresponds to the index in the image_data list
                    "doc": filepath, # Store the filepath in the 'doc' field
                })
        self.client.insert(self.collection_name, entities)

##Answer Generate

import os
from typing import List
from PIL import Image
import google.generativeai as genai
from google.colab import userdata # Added this import

def generate_gemini_answer(
    query: str,
    image_paths: List[str],
    api_key: str | None = None,
    model_name: str = "gemini-1.5-flash"
) -> str:
    """
    query        : Kullanıcının sorusu (tek string)
    image_paths  : Aynı soruyla gönderilecek PNG/JPG dosya yolları
    api_key      : Opsiyonel; verilmezse os.environ['GEMINI_API_KEY'] kullanılır
    model_name   : İstediğin Gemini modeli
    returns      : LLM cevabı (string)
    """
    # ── 1.  API anahtarını ayarla

    os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')
    key = api_key or os.getenv("GEMINI_API_KEY")

    if not key:
        raise ValueError("Gemini API key bulunamadı. "
                         "api_key parametresi ver veya GEMINI_API_KEY değişkenini ayarla.")
    genai.configure(api_key=key)

    # ── 2.  Modeli hazırla
    model = genai.GenerativeModel(model_name)

    # ── 3.  Resimleri oku
    images = [Image.open(p) for p in image_paths]

    # ── 4.  Sorguyu resimlerle birlikte gönder
    chat = model.start_chat()
    response = chat.send_message([*images, query])

    # ── 5.  Metin cevabı döndür
    return response.text

##### Checking Steps #############

import numpy as np

def pool(vec_list, how="mean"):          # vec_list = [np.ndarray, ...]
    stack = np.vstack(vec_list)          # (T,128)
    if how == "mean":
        return stack.mean(axis=0)        # (128,)
    elif how == "max":
        return stack.max(axis=0)

pdf_manager = PdfManager()
path = "/content/ABSA.pdf"
image_paths = pdf_manager.save_images(id="temp", pdf_path=path, max_pages=None)
embed_images = ColpaliManager(device=device, model_name=model_name)

colbert_vecs = embed_images.process_images(image_paths=image_paths, batch_size=5)

milvus = MilvusManager(
    milvus_uri="/content/milvus_demo.db",   # dosya yoksa Milvus oluşturur
    collection_name="colpali_demo",
    create_collection=True,                 # koleksiyonu baştan sıfırla
    dim=128                                 # ColPali vektör boyutu
)

##### Checking Steps #############
import numpy as np
import os
from PIL import Image # Added Image import

def pool(vec_list, how="mean"):          # vec_list = [np.ndarray, ...]
    stack = np.vstack(vec_list)          # (T,128)
    if how == "mean":
        return stack.mean(axis=0)        # (128,)
    elif how == "max":
        return stack.max(axis=0)

# Initialize objects directly in this cell
pdf_manager = PdfManager()
path = "/content/ABSA.pdf"
image_paths = pdf_manager.save_images(id="temp", pdf_path=path, max_pages=None)

# Assuming device and model_name are defined in previous cells
embed_images = ColpaliManager(device=device, model_name=model_name)
colbert_vecs = embed_images.process_images(image_paths=image_paths, batch_size=5)

milvus = MilvusManager(
    milvus_uri="/content/milvus_demo.db",
    collection_name="colpali_demo",
    create_collection=True,
    dim=128
)


images_data = [{
 "colbert_vecs": colbert_vecs[i],
   "filepath": image_paths[i]
} for i in range(len(image_paths))]


milvus.insert_images_data(images_data)
query= " Laguna Tedarikçisinin Sülfür Oranı 0.71 Olarak Değiştirilmesi durumunda ne olur?"
# query_vec= embed_images.process_text(query) # This line was causing an error because process_text expects a list
print(f"Searching for query: {query}")


#query_vec = embed_images.process_text([query][0]) # Redundant code
#query_vec_reshaped = pool(query_vec, "mean").astype(np.float32).reshape(1, -1) # Redundant code

q_vec = pool(embed_images.process_text([query]), "mean")   # (128,) - Corrected to pass a list
q_vec = q_vec.astype(np.float32).reshape(1, -1)


search_res = milvus.search(q_vec, topk=1)
best_doc_id    = int(search_res[0][1])

resp = milvus.client.query(
   collection_name="colpali_demo",
   filter=f"doc_id == {best_doc_id}",
   output_fields=["doc"],       # 'doc' alanında filepath tutuluyor
   limit=1
)

print("Topk sonuçlar:")
print(search_res)

import matplotlib.pyplot as plt
from PIL import Image

best_page_path = resp[0]["doc"] if resp else None
print("📄 En benzer sayfa:", best_page_path)

# Ensure best_page_path is not None before trying to open it
if best_page_path:
    best_page_img = Image.open(best_page_path)
    answer = generate_gemini_answer(
        query       = query,
        image_paths = [best_page_path],   # birden fazla resim varsa listeye ekle
    )

    print(f"Search result: {search_res} for query: {query}")
    print("Gemini cevabı:\n", answer)

    img = Image.open(best_page_path)

    plt.imshow(img)
    plt.axis('off')  # Eksenleri gizle
    plt.show()
else:
    print("Could not retrieve the best page path.")

#UI

import traceback
import numpy as np
import os
import tempfile
from pathlib import Path
import gradio as gr
from typing import Union
#from your_module import PdfManager, ColpaliManager, MilvusManager, generate_gemini_answer

# Global
embed_images = None
milvus       = None
image_paths  = None

def pool(vec_list, how="mean"):
    arr = np.vstack(vec_list)
    return arr.mean(axis=0) if how=="mean" else arr.max(axis=0)

def upload_and_index(file, max_pages):
    global embed_images, milvus, image_paths

    try:
        if file is None:
            return "⚠️ Lütfen önce bir PDF seçin."

        # Dosya yolunu çöz
        if isinstance(file, str):
            pdf_path = Path(file)
        elif hasattr(file, "name") and os.path.exists(file.name):
            pdf_path = Path(file.name)
        else:
            data = file.read()
            if isinstance(data, str):
                data = data.encode("utf-8")
            pdf_path = Path(tempfile.gettempdir()) / getattr(file, "orig_name", "upload.pdf")
            pdf_path.write_bytes(data)

        # Geçerlik kontrolü
        if not pdf_path.exists() or pdf_path.stat().st_size == 0:
            return f"❌ Hata: Geçersiz veya boş PDF ({pdf_path})."

        # PDF → Görseller
        pdf_manager = PdfManager()
        image_paths = pdf_manager.save_images(
            id=pdf_path.stem,
            pdf_path=str(pdf_path),
            max_pages=max_pages
        )

        # Görselleri embed et
        embed_images = ColpaliManager(device=device, model_name=model_name)
        colbert_vecs = embed_images.process_images(
            image_paths=image_paths,
            batch_size=5
        )

        # Milvus’a ekle (payload alanı “doc”)
        milvus = MilvusManager(
            milvus_uri="/content/milvus_demo.db",
            collection_name="colpali_demo",
            create_collection=True,
            dim=128
        )
        records = [
            {
                "colbert_vecs": v.astype(np.float32),
                "filepath":          str(image_paths[i])
            }
            for i, v in enumerate(colbert_vecs)
        ]
        milvus.insert_images_data(records)

        return f"✅ {len(image_paths)} sayfa işlendi ve eklendi."

    except Exception as e:
        traceback.print_exc()
        return f"❌ Hata: {e}"

def query_and_respond(query: str):
    global embed_images, milvus, image_paths

    if embed_images is None or milvus is None:
        return None, "⚠️ Önce PDF’i indexleyin."
    if not query.strip():
        return None, "⚠️ Lütfen bir soru girin."

    try:
        # Soru → vektör
        q_vec = pool(embed_images.process_text([query]), "mean")\
                    .astype(np.float32).reshape(1, -1)

        # Milvus araması
        search_res = milvus.search(q_vec, topk=1)
        if not search_res:
            return None, "⚠️ Eşleşme bulunamadı."

        best_doc_id = int(search_res[0][1])

        # Yol bilgisini al (output_fields=['doc'])
        rec = milvus.client.query(
            collection_name="colpali_demo",
            filter=f"doc_id == {best_doc_id}",
            output_fields=["doc"],
            limit=1
        )
        if not rec:
            return None, "⚠️ Dosya bulunamadı."

        best_page_path = rec[0]["filepath"]

        # Gemini cevabı
        answer = generate_gemini_answer(
            query=query,
            image_paths=[best_page_path]
        )

        return best_page_path, answer

    except Exception as e:
        traceback.print_exc()
        return None, f"❌ Cevap hatası: {e}"

# Gradio UI
with gr.Blocks() as demo:
    gr.Markdown("## 📄 Multimodal RAG: PDF + Görsel Soru–Cevap")

    with gr.Tab("1️⃣ PDF Yükle"):
        pdf_input   = gr.File(label="PDF Seç", file_count="single", file_types=[".pdf"])
        max_pages   = gr.Slider(1, 50, value=20, step=1, label="Max sayfa")
        status      = gr.Textbox(label="Durum", interactive=False)
        index_btn   = gr.Button("İşle")

        index_btn.click(
            upload_and_index,
            inputs=[pdf_input, max_pages],
            outputs=[status],
            queue=True
        )

    with gr.Tab("2️⃣ Soru Sor"):
        query_in = gr.Textbox(label="Sorunuzu Yazın")
        ask_btn  = gr.Button("Sor")
        out_img  = gr.Image(label="En benzer sayfa", type="filepath")
        out_txt  = gr.Textbox(label="RAG Cevabı", interactive=False)

        ask_btn.click(
            query_and_respond,
            inputs=[query_in],
            outputs=[out_img, out_txt],
            queue=True
        )

if __name__ == "__main__":
    demo.launch()

