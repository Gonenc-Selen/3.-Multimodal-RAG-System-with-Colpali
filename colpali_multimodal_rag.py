# -*- coding: utf-8 -*-
"""Colpali Multimodal RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p8JllI1uGkk97v31EBvuVN8Q2OWgeGUT
"""

# 0) ORTAMI HAZIRLA  (tek sefer)
!apt-get -y install poppler-utils
!pip install pdf2image faiss-cpu colpali_engine google-generativeai
!pip install PyMuPDF
!pip install pdf2image pillow --quiet
!apt-get update -qq && apt-get install -y poppler-utils -qq
!pip install pymilvus

### Gerekli kÃ¼tÃ¼phaneleri yÃ¼kle

from colpali_engine.models import ColPali
from colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor
from colpali_engine.utils.processing_utils import BaseVisualRetrieverProcessor
from colpali_engine.utils.torch_utils import ListDataset, get_torch_device
from torch.utils.data import DataLoader
import torch
from typing import List, cast
from tqdm import tqdm
from PIL import Image
import os
import requests
import os
import google.generativeai as genai
from typing import List
from PIL import Image
import gradio as gr
import tempfile
import os
import fitz  # PyMuPDF
import uuid
from pdf2image import convert_from_path
import shutil
import os, shutil

### PDF'leri yÃ¼kleme, Image iÃ§in klasÃ¶r oluÅŸturma, Image kaydetme
from pdf2image import convert_from_path
class PdfManager:
    def __init__(self):
        pass

    def clear_and_recreate_dir(self, output_folder):
        print(f"Clearing output folder {output_folder}")

        if os.path.exists(output_folder):
            shutil.rmtree(output_folder)

        os.makedirs(output_folder)

    def save_images(self, id, pdf_path, max_pages, pages: list[int] = None) -> list[str]:
        output_folder = f"pages/{id}/"
        images = convert_from_path(pdf_path)

        print(f"Saving images from {pdf_path} to {output_folder}. Max pages: {max_pages}")

        self.clear_and_recreate_dir(output_folder)

        num_page_processed = 0

        for i, image in enumerate(images):
            if max_pages and num_page_processed >= max_pages:
                break

            if pages and i not in pages:
                continue

            full_save_path = f"{output_folder}/page_{i + 1}.png"

            #print(f"Saving image to {full_save_path}")

            image.save(full_save_path, "PNG")

            num_page_processed += 1

        return [f"{output_folder}/page_{i + 1}.png" for i in range(num_page_processed)]

#### Colpali / Model Ä°ndirme ve Embed Ä°ÅŸlemleri

from colpali_engine.models import ColPali
from colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor
from colpali_engine.utils.processing_utils import BaseVisualRetrieverProcessor
from colpali_engine.utils.torch_utils import ListDataset, get_torch_device
from torch.utils.data import DataLoader
import torch
from typing import List, cast

from tqdm import tqdm
from PIL import Image
import os


model_name = "vidore/colpali-v1.2"
device = get_torch_device("cuda")

model = ColPali.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map=device,
).eval()

processor = cast(ColPaliProcessor, ColPaliProcessor.from_pretrained(model_name))

class ColpaliManager:


    def __init__(self, device = "cuda", model_name = "vidore/colpali-v1.2"):

        print(f"Initializing ColpaliManager with device {device} and model {model_name}")

    def get_images(self, paths: list[str]) -> List[Image.Image]:
        return [Image.open(path) for path in paths]

    def process_images(self, image_paths:list[str], batch_size=5):

        print(f"Processing {len(image_paths)} image_paths")

        images = self.get_images(image_paths)

        dataloader = DataLoader(
            dataset=ListDataset[str](images),
            batch_size=batch_size,
            shuffle=False,
            collate_fn=lambda x: processor.process_images(x),
        )

        ds: List[torch.Tensor] = []
        for batch_doc in tqdm(dataloader):
            with torch.no_grad():
                batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}
                embeddings_doc = model(**batch_doc)
            ds.extend(list(torch.unbind(embeddings_doc.to(device))))

        ds_np = [d.float().cpu().numpy() for d in ds]

        return ds_np

    def process_text(self, texts: list[str]):
        print(f"Processing {len(texts)} texts")

        dataloader = DataLoader(
            dataset=ListDataset[str](texts),
            batch_size=1,
            shuffle=False,
            collate_fn=lambda x: processor.process_queries(x),
        )

        qs: List[torch.Tensor] = []
        for batch_query in dataloader:
            with torch.no_grad():
                batch_query = {k: v.to(model.device) for k, v in batch_query.items()}
                embeddings_query = model(**batch_query)

            qs.extend(list(torch.unbind(embeddings_query.to(device))))

        qs_np = [q.float().cpu().numpy() for q in qs]

        return qs_np

#### pymilvus embedding and searching

from pymilvus import MilvusClient, DataType
import numpy as np
import concurrent.futures


class MilvusManager:
    def __init__(self, milvus_uri, collection_name, create_collection, dim=128):
        self.client = MilvusClient(uri=milvus_uri)
        self.collection_name = collection_name
        # Check if collection exists and load it if not creating a new one
        if not create_collection and self.client.has_collection(collection_name=self.collection_name):
             self.client.load_collection(collection_name)

        self.dim = dim

        if create_collection:
            self.create_collection()
            self.create_index()


    def create_collection(self):
        # drop collection if it exists and create a new one
        if self.client.has_collection(collection_name=self.collection_name):
            self.client.drop_collection(collection_name=self.collection_name)
        schema = self.client.create_schema(
            auto_id=True,
            enable_dynamic_fields=True,
        )
        schema.add_field(field_name="pk", datatype=DataType.INT64, is_primary=True)
        schema.add_field(
            field_name="vector", datatype=DataType.FLOAT_VECTOR, dim=self.dim
        )
        schema.add_field(field_name="seq_id", datatype=DataType.INT16)
        schema.add_field(field_name="doc_id", datatype=DataType.INT64)
        schema.add_field(field_name="doc", datatype=DataType.VARCHAR, max_length=65535)

        self.client.create_collection(
            collection_name=self.collection_name, schema=schema
        )

    def create_index(self):
        # Release the collection before creating an index
        self.client.release_collection(collection_name=self.collection_name)

        # Prepare and create the index
        index_params = self.client.prepare_index_params()
        index_params.add_index(
            field_name="vector",
            index_name="vector_index",
            index_type="FLAT",  # Using FLAT index as a starting point
            metric_type="IP",
            params={
                "M": 16, # These parameters are specific to HNSW, might need adjustment for FLAT
                "efConstruction": 500,
            },
        )

        self.client.create_index(
            collection_name=self.collection_name, index_params=index_params, sync=True
        )

    def create_scalar_index(self):
        self.client.release_collection(collection_name=self.collection_name)
        index_params = self.client.prepare_index_params()
        index_params.add_index(
            field_name="doc_id",
            index_name="int32_index",
            index_type="FLAT",
        )

        self.client.create_index(
            collection_name=self.collection_name, index_params=index_params, sync=True
        )


    def search(self, data, topk):
        search_params = {"metric_type": "IP", "params": {}}
        results = self.client.search(
            self.collection_name,
            data,
            limit=int(50),
            output_fields=["vector", "seq_id", "doc_id"],
            search_params=search_params,
        )
        doc_ids = set()
        for r_id in range(len(results)):
            for r in range(len(results[r_id])):
                doc_ids.add(results[r_id][r]["entity"]["doc_id"])

        scores = []

        def rerank_single_doc(doc_id, data, client, collection_name):
            doc_colbert_vecs = client.query(
                collection_name=collection_name,
                filter=f"doc_id in [{doc_id}]",
                output_fields=["seq_id", "vector", "doc"], # Ensure 'doc' is requested here
                limit=1000,
            )
            if not doc_colbert_vecs: # Added check for empty results
                return (0, doc_id) # Return a score of 0 if no vectors are found

            doc_vecs = np.vstack(
                [doc_colbert_vecs[i]["vector"] for i in range(len(doc_colbert_vecs))]
            )
            score = np.dot(data, doc_vecs.T).max(1).sum()
            return (score, doc_id)

        with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:
            futures = {
                executor.submit(
                    rerank_single_doc, doc_id, data, self.client, self.collection_name
                ): doc_id
                for doc_id in doc_ids
            }
            for future in concurrent.futures.as_completed(futures):
                score, doc_id = future.result()
                scores.append((score, doc_id))

        scores.sort(key=lambda x: x[0], reverse=True)
        if len(scores) >= topk:
            return scores[:topk]
        else:
            return scores

    def insert_images_data(self, image_data):
        # image_data is a list of dictionaries, each with 'colbert_vecs' and 'filepath'
        entities = []
        for i, data in enumerate(image_data):
            colbert_vecs = data["colbert_vecs"]
            filepath = data["filepath"]
            seq_length = len(colbert_vecs)
            for j in range(seq_length):
                entities.append({
                    "vector": colbert_vecs[j],
                    "seq_id": j,
                    "doc_id": i, # doc_id corresponds to the index in the image_data list
                    "doc": filepath, # Store the filepath in the 'doc' field
                })
        self.client.insert(self.collection_name, entities)

##Answer Generate

import os
from typing import List
from PIL import Image
import google.generativeai as genai
from google.colab import userdata # Added this import

def generate_gemini_answer(
    query: str,
    image_paths: List[str],
    api_key: str | None = None,
    model_name: str = "gemini-1.5-flash"
) -> str:
    """
    query        : KullanÄ±cÄ±nÄ±n sorusu (tek string)
    image_paths  : AynÄ± soruyla gÃ¶nderilecek PNG/JPG dosya yollarÄ±
    api_key      : Opsiyonel; verilmezse os.environ['GEMINI_API_KEY'] kullanÄ±lÄ±r
    model_name   : Ä°stediÄŸin Gemini modeli
    returns      : LLM cevabÄ± (string)
    """
    # â”€â”€ 1.  API anahtarÄ±nÄ± ayarla

    os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')
    key = api_key or os.getenv("GEMINI_API_KEY")

    if not key:
        raise ValueError("Gemini API key bulunamadÄ±. "
                         "api_key parametresi ver veya GEMINI_API_KEY deÄŸiÅŸkenini ayarla.")
    genai.configure(api_key=key)

    # â”€â”€ 2.  Modeli hazÄ±rla
    model = genai.GenerativeModel(model_name)

    # â”€â”€ 3.  Resimleri oku
    images = [Image.open(p) for p in image_paths]

    # â”€â”€ 4.  Sorguyu resimlerle birlikte gÃ¶nder
    chat = model.start_chat()
    response = chat.send_message([*images, query])

    # â”€â”€ 5.  Metin cevabÄ± dÃ¶ndÃ¼r
    return response.text

##### Checking Steps #############

import numpy as np

def pool(vec_list, how="mean"):          # vec_list = [np.ndarray, ...]
    stack = np.vstack(vec_list)          # (T,128)
    if how == "mean":
        return stack.mean(axis=0)        # (128,)
    elif how == "max":
        return stack.max(axis=0)

pdf_manager = PdfManager()
path = "/content/ABSA.pdf"
image_paths = pdf_manager.save_images(id="temp", pdf_path=path, max_pages=None)
embed_images = ColpaliManager(device=device, model_name=model_name)

colbert_vecs = embed_images.process_images(image_paths=image_paths, batch_size=5)

milvus = MilvusManager(
    milvus_uri="/content/milvus_demo.db",   # dosya yoksa Milvus oluÅŸturur
    collection_name="colpali_demo",
    create_collection=True,                 # koleksiyonu baÅŸtan sÄ±fÄ±rla
    dim=128                                 # ColPali vektÃ¶r boyutu
)

##### Checking Steps #############
import numpy as np
import os
from PIL import Image # Added Image import

def pool(vec_list, how="mean"):          # vec_list = [np.ndarray, ...]
    stack = np.vstack(vec_list)          # (T,128)
    if how == "mean":
        return stack.mean(axis=0)        # (128,)
    elif how == "max":
        return stack.max(axis=0)

# Initialize objects directly in this cell
pdf_manager = PdfManager()
path = "/content/ABSA.pdf"
image_paths = pdf_manager.save_images(id="temp", pdf_path=path, max_pages=None)

# Assuming device and model_name are defined in previous cells
embed_images = ColpaliManager(device=device, model_name=model_name)
colbert_vecs = embed_images.process_images(image_paths=image_paths, batch_size=5)

milvus = MilvusManager(
    milvus_uri="/content/milvus_demo.db",
    collection_name="colpali_demo",
    create_collection=True,
    dim=128
)


images_data = [{
 "colbert_vecs": colbert_vecs[i],
   "filepath": image_paths[i]
} for i in range(len(image_paths))]


milvus.insert_images_data(images_data)
query= " Laguna TedarikÃ§isinin SÃ¼lfÃ¼r OranÄ± 0.71 Olarak DeÄŸiÅŸtirilmesi durumunda ne olur?"
# query_vec= embed_images.process_text(query) # This line was causing an error because process_text expects a list
print(f"Searching for query: {query}")


#query_vec = embed_images.process_text([query][0]) # Redundant code
#query_vec_reshaped = pool(query_vec, "mean").astype(np.float32).reshape(1, -1) # Redundant code

q_vec = pool(embed_images.process_text([query]), "mean")   # (128,) - Corrected to pass a list
q_vec = q_vec.astype(np.float32).reshape(1, -1)


search_res = milvus.search(q_vec, topk=1)
best_doc_id    = int(search_res[0][1])

resp = milvus.client.query(
   collection_name="colpali_demo",
   filter=f"doc_id == {best_doc_id}",
   output_fields=["doc"],       # 'doc' alanÄ±nda filepath tutuluyor
   limit=1
)

print("Topk sonuÃ§lar:")
print(search_res)

import matplotlib.pyplot as plt
from PIL import Image

best_page_path = resp[0]["doc"] if resp else None
print("ğŸ“„ En benzer sayfa:", best_page_path)

# Ensure best_page_path is not None before trying to open it
if best_page_path:
    best_page_img = Image.open(best_page_path)
    answer = generate_gemini_answer(
        query       = query,
        image_paths = [best_page_path],   # birden fazla resim varsa listeye ekle
    )

    print(f"Search result: {search_res} for query: {query}")
    print("Gemini cevabÄ±:\n", answer)

    img = Image.open(best_page_path)

    plt.imshow(img)
    plt.axis('off')  # Eksenleri gizle
    plt.show()
else:
    print("Could not retrieve the best page path.")

#UI

import traceback
import numpy as np
import os
import tempfile
from pathlib import Path
import gradio as gr
from typing import Union
#from your_module import PdfManager, ColpaliManager, MilvusManager, generate_gemini_answer

# Global
embed_images = None
milvus       = None
image_paths  = None

def pool(vec_list, how="mean"):
    arr = np.vstack(vec_list)
    return arr.mean(axis=0) if how=="mean" else arr.max(axis=0)

def upload_and_index(file, max_pages):
    global embed_images, milvus, image_paths

    try:
        if file is None:
            return "âš ï¸ LÃ¼tfen Ã¶nce bir PDF seÃ§in."

        # Dosya yolunu Ã§Ã¶z
        if isinstance(file, str):
            pdf_path = Path(file)
        elif hasattr(file, "name") and os.path.exists(file.name):
            pdf_path = Path(file.name)
        else:
            data = file.read()
            if isinstance(data, str):
                data = data.encode("utf-8")
            pdf_path = Path(tempfile.gettempdir()) / getattr(file, "orig_name", "upload.pdf")
            pdf_path.write_bytes(data)

        # GeÃ§erlik kontrolÃ¼
        if not pdf_path.exists() or pdf_path.stat().st_size == 0:
            return f"âŒ Hata: GeÃ§ersiz veya boÅŸ PDF ({pdf_path})."

        # PDF â†’ GÃ¶rseller
        pdf_manager = PdfManager()
        image_paths = pdf_manager.save_images(
            id=pdf_path.stem,
            pdf_path=str(pdf_path),
            max_pages=max_pages
        )

        # GÃ¶rselleri embed et
        embed_images = ColpaliManager(device=device, model_name=model_name)
        colbert_vecs = embed_images.process_images(
            image_paths=image_paths,
            batch_size=5
        )

        # Milvusâ€™a ekle (payload alanÄ± â€œdocâ€)
        milvus = MilvusManager(
            milvus_uri="/content/milvus_demo.db",
            collection_name="colpali_demo",
            create_collection=True,
            dim=128
        )
        records = [
            {
                "colbert_vecs": v.astype(np.float32),
                "filepath":          str(image_paths[i])
            }
            for i, v in enumerate(colbert_vecs)
        ]
        milvus.insert_images_data(records)

        return f"âœ… {len(image_paths)} sayfa iÅŸlendi ve eklendi."

    except Exception as e:
        traceback.print_exc()
        return f"âŒ Hata: {e}"

def query_and_respond(query: str):
    global embed_images, milvus, image_paths

    if embed_images is None or milvus is None:
        return None, "âš ï¸ Ã–nce PDFâ€™i indexleyin."
    if not query.strip():
        return None, "âš ï¸ LÃ¼tfen bir soru girin."

    try:
        # Soru â†’ vektÃ¶r
        q_vec = pool(embed_images.process_text([query]), "mean")\
                    .astype(np.float32).reshape(1, -1)

        # Milvus aramasÄ±
        search_res = milvus.search(q_vec, topk=1)
        if not search_res:
            return None, "âš ï¸ EÅŸleÅŸme bulunamadÄ±."

        best_doc_id = int(search_res[0][1])

        # Yol bilgisini al (output_fields=['doc'])
        rec = milvus.client.query(
            collection_name="colpali_demo",
            filter=f"doc_id == {best_doc_id}",
            output_fields=["doc"],
            limit=1
        )
        if not rec:
            return None, "âš ï¸ Dosya bulunamadÄ±."

        best_page_path = rec[0]["filepath"]

        # Gemini cevabÄ±
        answer = generate_gemini_answer(
            query=query,
            image_paths=[best_page_path]
        )

        return best_page_path, answer

    except Exception as e:
        traceback.print_exc()
        return None, f"âŒ Cevap hatasÄ±: {e}"

# Gradio UI
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ“„ Multimodal RAG: PDF + GÃ¶rsel Soruâ€“Cevap")

    with gr.Tab("1ï¸âƒ£ PDF YÃ¼kle"):
        pdf_input   = gr.File(label="PDF SeÃ§", file_count="single", file_types=[".pdf"])
        max_pages   = gr.Slider(1, 50, value=20, step=1, label="Max sayfa")
        status      = gr.Textbox(label="Durum", interactive=False)
        index_btn   = gr.Button("Ä°ÅŸle")

        index_btn.click(
            upload_and_index,
            inputs=[pdf_input, max_pages],
            outputs=[status],
            queue=True
        )

    with gr.Tab("2ï¸âƒ£ Soru Sor"):
        query_in = gr.Textbox(label="Sorunuzu YazÄ±n")
        ask_btn  = gr.Button("Sor")
        out_img  = gr.Image(label="En benzer sayfa", type="filepath")
        out_txt  = gr.Textbox(label="RAG CevabÄ±", interactive=False)

        ask_btn.click(
            query_and_respond,
            inputs=[query_in],
            outputs=[out_img, out_txt],
            queue=True
        )

if __name__ == "__main__":
    demo.launch()

